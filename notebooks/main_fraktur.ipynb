{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce99f5d9-4191-4c1c-81d8-1eb78e165ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # split the pdf into separate pages\n",
    "\n",
    "# import PyPDF2\n",
    "# from src.document_generation import setup_logger\n",
    "# import logging\n",
    "\n",
    "# logger = logging.getLogger('logger_name')\n",
    "# if logger.hasHandlers():\n",
    "#     logger.handlers.clear()  # Clear existing handlers to avoid duplicates\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "# handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "# logger.addHandler(handler)\n",
    "# logger.propagate = False\n",
    "\n",
    "# # Input PDF file path\n",
    "# input_pdf_path = \"../input_data/Der Weltkrieg v7 East Front.pdf\"\n",
    "# output_folder = \"../input_data/Der Weltkrieg v7\"\n",
    "\n",
    "# # Ensure the output folder exists\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Open the PDF and split pages\n",
    "# try:\n",
    "#     with open(input_pdf_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         num_pages = len(pdf_reader.pages)\n",
    "#         logger.info(f\"Extracted {num_pages} pages from PDF\")\n",
    "\n",
    "#         for i, page in enumerate(pdf_reader.pages):\n",
    "#             # Create a new PDF writer for each page\n",
    "#             pdf_writer = PyPDF2.PdfWriter()\n",
    "#             pdf_writer.add_page(page)\n",
    "\n",
    "#             # Save the current page to a new file\n",
    "#             output_file_path = os.path.join(output_folder, f\"page_{i+1:03d}.pdf\")\n",
    "#             with open(output_file_path, 'wb') as output_file:\n",
    "#                 pdf_writer.write(output_file)\n",
    "            \n",
    "#             logger.debug(f\"Saved page {i+1} to {output_file_path}\")\n",
    "#             if i == 10:\n",
    "#                 break\n",
    "\n",
    "#     logger.info(f\"All pages have been split and saved to {output_folder}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd7026f-2a85-4c43-8110-547d0decaa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /Users/ozkansafak/code/fraktur/.venv/bin/python3\n",
      "sys.version: 3.10.9 (main, Mar  1 2023, 12:20:14) [Clang 14.0.6 ] \n",
      "\n",
      "CPU times: user 982 ms, sys: 2.41 s, total: 3.39 s\n",
      "Wall time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard Python modules\n",
    "import time \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import openai\n",
    "import logging\n",
    "from typing import Dict, Tuple, List, Callable\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Decorator to log wall time\n",
    "def log_execution_time(func: Callable):\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = await func(*args, **kwargs)\n",
    "        logger.info(f\"Finished {func.__name__} in {time.time() - start:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def get_missing_keys(raw_german_texts):\n",
    "    # print missing keys\n",
    "    missing_keys = [ key for key in sorted(all_pagenos) if key not in raw_german_texts or len(raw_german_texts[key]) < 10 ]\n",
    "    return missing_keys\n",
    "\n",
    "# Load environment variables from .env file\n",
    "env_path = Path('../.env')  # Adjust path if needed\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# # Get the root path of the project\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Display and plotting\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Project imports\n",
    "from src.utils import timeit, encode_image, plt, pylab\n",
    "from src.processing import compute_log_spectrum_1d, extract_image_bbox, save_images\n",
    "from src.api_requests import construct_payload_for_gpt, process_single_page\n",
    "from src.document_generation import save_document\n",
    "\n",
    "# Set notebook display width\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# Print Python environment info\n",
    "print('sys.executable:', sys.executable)\n",
    "print('sys.version:', sys.version, '\\n')\n",
    "\n",
    "# Setup for PDF processing\n",
    "foldername = \"Der Weltkrieg v7\"\n",
    "\n",
    "# OpenAI API setup\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "}\n",
    "\n",
    "# --------------------\n",
    "# Initialize variables\n",
    "# --------------------\n",
    "plotter = False\n",
    "image_path = f\"../input_data/{foldername}/*pdf\"\n",
    "fnames = sorted(glob.glob(image_path))\n",
    "all_pagenos = [re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1) for fname in fnames]\n",
    "\n",
    "# Storage for processed texts\n",
    "raw_german_texts: Dict[str, str] = {}\n",
    "german_texts: Dict[str, str] = {}\n",
    "english_texts: Dict[str, str] = {}\n",
    "\n",
    "# ------------------\n",
    "# Configure logging\n",
    "# ------------------\n",
    "logger = logging.getLogger(\"time_logger\")\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()  # Clear existing handlers to avoid duplicates\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Don't propagate message to parent loggers\n",
    "logger.propagate = False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e18f5",
   "metadata": {},
   "source": [
    "---\n",
    "## Fraktur Translator (GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1adb975a-b3e6-4d87-904b-48b7095f2bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:06:53,617 - INFO - main: len(tasks): 2 -- Processing tasks as they complete\n",
      "2024-12-21 19:07:23,058 - INFO -    0 of 2 -- Successfully processed page:005\n",
      "2024-12-21 19:08:25,485 - INFO - Pageno: 006, \"raw_german\" section was not found\n",
      "2024-12-21 19:08:25,487 - INFO - Pageno: 006, \"german\" section was not found\n",
      "2024-12-21 19:08:25,488 - INFO - Pageno: 006, \"english\" section was not found\n",
      "2024-12-21 19:08:25,494 - INFO -    1 of 2 -- Successfully processed page:006\n",
      "2024-12-21 19:08:25,495 - INFO - Finished main in 91.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "@log_execution_time\n",
    "async def main(fnames, model_name=\"\", semaphore_count=5, extract=True):\n",
    "    semaphore = asyncio.Semaphore(semaphore_count)  # Adjust number based on API limits\n",
    "    async def _process_page(fname: str) -> Tuple[str, Dict]:\n",
    "        global raw_german_texts, german_texts, english_texts  # Explicitly declare globals\n",
    "        async with semaphore:\n",
    "            pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "            result = await process_single_page(fname, model_name, headers, plotter, pageno, extract) \n",
    "            return pageno, result\n",
    "    \n",
    "    # A list of coroutine objects. include only the unprocessed pages.\n",
    "    keys = set(raw_german_texts.keys())\n",
    "    tasks = []\n",
    "    for fname in fnames:\n",
    "        pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "        if pageno not in keys:\n",
    "            tasks.append(_process_page(fname))\n",
    "    logger.info(f\"main: len(tasks): {len(tasks)} -- Processing tasks as they complete\")\n",
    "    \n",
    "    # Process tasks as they complete\n",
    "    for i, completed_task in enumerate(asyncio.as_completed(tasks)):\n",
    "        try:\n",
    "            pageno, (content, raw_german_text, german_text, english_text) = await completed_task\n",
    "            raw_german_texts[pageno] = raw_german_text\n",
    "            german_texts[pageno] = german_text\n",
    "            english_texts[pageno] = english_text\n",
    "            logger.info(f\" {i:3d} of {len(tasks)} -- Successfully processed page:{pageno}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{i:3d} of {len(tasks)} -- Error processing a task: {e}\")\n",
    "    return \n",
    "\n",
    "# Run the async code\n",
    "await main(fnames[5:8], model_name=\"gpt-4o-2024-08-06\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bdf17-5961-49e5-a101-cccfe6cded0c",
   "metadata": {},
   "source": [
    "##  Handle missing keys (Claude Sonnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004d68e6-4fd4-4a7d-bf9b-cf220be5f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:08:28,415 - INFO - main: len(tasks): 2 -- Processing tasks as they complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: {'006', '405'}\n",
      "processing pageno: 006\n",
      "processing pageno: 405\n",
      "missed_fnames: \n",
      "../input_data/Der Weltkrieg v7/page_006.pdf\n",
      "../input_data/Der Weltkrieg v7/page_405.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:08:33,906 - INFO - Pageno: 405, \"raw_german\" section was not found\n",
      "2024-12-21 19:08:33,908 - INFO - Pageno: 405, \"german\" section was not found\n",
      "2024-12-21 19:08:33,909 - INFO - Pageno: 405, \"english\" section was not found\n",
      "2024-12-21 19:08:35,270 - INFO -    0 of 2 -- Successfully processed page:405\n",
      "2024-12-21 19:08:59,328 - INFO -    1 of 2 -- Successfully processed page:006\n",
      "2024-12-21 19:08:59,329 - INFO - Finished main in 30.91 seconds.\n",
      "2024-12-21 19:08:59,332 - INFO - main: len(tasks): 1 -- Processing tasks as they complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: {'405'}\n",
      "processing pageno: 405\n",
      "missed_fnames: \n",
      "../input_data/Der Weltkrieg v7/page_405.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:09:03,858 - INFO - Pageno: 405, \"raw_german\" section was not found\n",
      "2024-12-21 19:09:03,860 - INFO - Pageno: 405, \"german\" section was not found\n",
      "2024-12-21 19:09:03,861 - INFO - Pageno: 405, \"english\" section was not found\n",
      "2024-12-21 19:09:03,866 - INFO -    0 of 1 -- Successfully processed page:405\n",
      "2024-12-21 19:09:03,867 - INFO - Finished main in 4.53 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# 1. Rerun the missing pages on Claude\n",
    "# ---------------------\n",
    "missing_keys = set(get_missing_keys(raw_german_texts))\n",
    "for key in missing_keys:\n",
    "    del raw_german_texts[key]\n",
    "print(f\"missing_keys: {missing_keys}\")\n",
    "missed_fnames = []\n",
    "for fname in fnames:\n",
    "    pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "    if pageno in missing_keys:\n",
    "        print(f\"processing pageno: {pageno}\")\n",
    "        missed_fnames.append(fname)\n",
    "print(f\"missed_fnames: \")\n",
    "[print(item) for item in missed_fnames]\n",
    "\n",
    "await main(missed_fnames, model_name=\"claude-3-5-sonnet-20241022\", semaphore_count=1, extract=True)\n",
    "\n",
    "# ---------------------\n",
    "# 2. If there still are missing pages, run them without performing FFT based extraction. \n",
    "#    This time compute missing_keys based on 'english_texts'.\n",
    "# ---------------------\n",
    "missing_keys = set(get_missing_keys(english_texts))\n",
    "for key in missing_keys:\n",
    "    del raw_german_texts[key]\n",
    "print(f\"missing_keys: {missing_keys}\")\n",
    "missed_fnames = []\n",
    "for fname in fnames:\n",
    "    pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "    if pageno in missing_keys:\n",
    "        print(f\"processing pageno: {pageno}\")\n",
    "        missed_fnames.append(fname)\n",
    "print(f\"missed_fnames: \")\n",
    "for item in missed_fnames:\n",
    "    print(item) \n",
    "\n",
    "await main(missed_fnames, model_name=\"claude-3-5-sonnet-20241022\", semaphore_count=1, extract=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420883ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save json files and .docx files.\n",
    "\n",
    "from src.document_generation import save_document\n",
    "\n",
    "# save json outputs\n",
    "# if not os.path.exists(f'../output_data/{foldername}'):\n",
    "#     os.makedirs(f'../output_data/{foldername}')\n",
    "# with open(f'../output_data/{foldername}/english_texts.json', 'w') as f:\n",
    "#     json.dump(english_texts, f)\n",
    "# with open(f'../output_data/{foldername}/german_texts.json', 'w') as f:\n",
    "#     json.dump(german_texts, f)\n",
    "# with open(f'../output_data/{foldername}/raw_german_texts.json', 'w') as f:\n",
    "#     json.dump(raw_german_texts, f)\n",
    "\n",
    "doc1, fname1 = save_document(german_texts, foldername, language='German')\n",
    "doc2, fname2 = save_document(english_texts, foldername, language='English')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63eac8",
   "metadata": {},
   "source": [
    "``` \n",
    "1.  Upload Input folder of pdfs to blob storage.\n",
    "2.  Read file from s3.\n",
    "3.  FFT in y -> (x_hi, x_lo), write half_cropped_image to s3\n",
    "4.  FFT in x -> (y_hi, y_lo), write cropped_image to s3\n",
    "5.  Read cropped image from s3 -> encode_image -> translate and transcribe -> JSON output\n",
    "\n",
    "```\n",
    "\n",
    "### Available models and pricing:\n",
    "```\n",
    "\"gpt-4o-2024-08-06\":\n",
    "    \"price_txt\": \"$2.50 / 1M input tokens\"\n",
    "    \"price_img\": \"$0.001913 / 1500px^2\"\n",
    "    \n",
    "\"gpt-4o-mini-2024-07-18\":\n",
    "    \"price_txt\": \"$0.150 / 1M input tokens\"\n",
    "    \"price_img\": \"$0.003825 / 1500px^2\"\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6e3a6-1c7d-4cce-badb-8b664f6e75c8",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the German text and translate broken sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a46058-0503-4b3a-a1b6-c748b9d1cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../output_data/{foldername}/english_texts.json', 'r') as f:\n",
    "    english_texts = json.load(f)\n",
    "with open(f'../output_data/{foldername}/german_texts.json', 'r') as f:\n",
    "    german_texts = json.load(f)\n",
    "with open(f'../output_data/{foldername}/raw_german_texts.json', 'r') as f:\n",
    "    raw_german_texts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7899a831-f178-4149-8e2f-b36714abe287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input lists. Extract the <body> sections from german_texts and english_texts.\n",
    "german_body_contents = {}\n",
    "for pageno in all_pagenos:\n",
    "    content = german_texts[pageno] \n",
    "    try: \n",
    "        body = re.search(r'<body>(.*?)</body>', content, re.DOTALL).group(1) \n",
    "    except:\n",
    "        body = ''\n",
    "    german_body_contents[pageno] = body\n",
    "\n",
    "english_body_contents = {}\n",
    "for pageno in all_pagenos:\n",
    "    content = english_texts[pageno] \n",
    "    try: \n",
    "        body = re.search(r'<body>(.*?)</body>', content, re.DOTALL).group(1) \n",
    "    except:\n",
    "        body = ''\n",
    "    english_body_contents[pageno] = body\n",
    "\n",
    "# initialize output dicts\n",
    "english_texts_2 = {}\n",
    "outputs = {}\n",
    "payloads = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f23f10ed-d003-451c-8d19-27092ada0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_payload_2(german_body_contents, \n",
    "                        english_body_contents, \n",
    "                        german_sentence_fragment_1, \n",
    "                        model_name, \n",
    "                        pageno, \n",
    "                        next_pageno):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a World War II historian, who's bilingual in German and English \"\n",
    "              \"You speak both languages with masterful efficiency and you're a professional translator from GERMAN to ENGLISH who \"\n",
    "              \"stays loyal to both the style and the character of the original German text in your book translations.\"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": \n",
    "f\"\"\"\n",
    "**Task Overview**\n",
    "In the **Given DAta** section below, you are presented the translation of `<german_page_1>` into `<english_page_1>`. Your objective is to address any issues caused by sentences that span across `<german_page_1>` and `<german_page_2>`.\n",
    "\n",
    "------------------\n",
    "\n",
    "**Chain of Thought Reasoning**\n",
    "1. Identify Potential Fragment 1 (The last sentence at the very bottom of `<german_page_1>`):\n",
    "   - Extract the portion of German text at the end of `<german_page_1>` that may or may not be a complete sentence on its own.\n",
    "   - This German piece of text is the candidate for `fragment_1`.\n",
    "   - Output `fragment_1` inside `<fragment_1>...</fragment_1>` tags.\n",
    "\n",
    "2. Identify Potential Fragment 2 (The first sentence at the very top of `<german_page_2>`):\n",
    "   - Extract the portion of German text at the top of `<german_page_2>` that appears to complete the thought or grammatical structure of `fragment_1`.\n",
    "   - This German piece of text is the candidate for `fragment_2`. Include **only** the text necessary to complete `fragment_1`.\n",
    "   - Output `fragment_2` inside `<fragment_2>...</fragment_2>` tags.\n",
    "\n",
    "3. Reasoning and Validation:\n",
    "   - Compare `fragment_1` and `fragment_2`:\n",
    "       - Does `fragment_2` logically and grammatically continue `fragment_1`?\n",
    "       - Does combining the two fragments form a coherent sentence?\n",
    "   - Ensure that `fragment_2` contains only the portion necessary to complete `fragment_1`.\n",
    "   - Decide whether the fragments align to form a single coherent sentence.\n",
    "   - Think out loud. Output your reasoning process and wrap your thoughts in `<thinking>...</thinking>` tags.\n",
    "\n",
    "4. Combine Fragments (if valid):\n",
    "   - If the fragments align and validation succeeds, combine them into a coherent, grammatically correct sentence.\n",
    "   - If they do not align or either fragment is missing, conclude that there is no valid fragmentation.\n",
    "   - Again, think out loud. Output your decision inside `<decision>...</decision>` tags.\n",
    "\n",
    "------------------\n",
    "\n",
    "**Output Requirements**\n",
    "1. **Chain of Thought Tokens**:\n",
    "   - Output your reasoning for each step inside `<thinking>...</thinking>` tags.\n",
    "   - Ensure that the reasoning is clear and concise.\n",
    "\n",
    "2. **Candidate Fragments**:\n",
    "   - Fragment 1: Wrap this in `<fragment_1>...</fragment_1>` tags.\n",
    "   - Fragment 2: Wrap this in `<fragment_2>...</fragment_2>` tags.\n",
    "\n",
    "3. **Final Decision**:\n",
    "   - Indicate whether the fragments align to form a coherent sentence inside `<decision>...</decision>` tags.\n",
    "   - If the fragments do not align, explicitly state this in the `<decision>` tags.\n",
    "\n",
    "4. **Final Combined Sentence**:\n",
    "   Two Cases:\n",
    "   - **Case 1**:\n",
    "       - If the fragments align, wrap the combined sentence in `<english>...</english>` tags.\n",
    "       - Include the validated German fragment from `<german_page_2>` in `<final_fragment_2>` tags.\n",
    "   - **Case 2**:\n",
    "       - If no valid fragmentation exists, output `<english_page_1>` unchanged.\n",
    "       - Set `<final_fragment_2>` as empty.\n",
    "\n",
    "------------------\n",
    "\n",
    "**Example 1. Output for a Fragmented Sentence**\n",
    "\n",
    "<thinking>\n",
    "Step 1: Identify `fragment_1` from the bottom of `german_page_1`.\n",
    "<fragment_1>Der Angriff begann früh am Morgen</fragment_1>\n",
    "\n",
    "Step 2: Identify `fragment_2` from the top of `german_page_2`.\n",
    "<fragment_2>des 10. Mai mit schwerem Artilleriefeuer.</fragment_2>\n",
    "\n",
    "Step 3: Validate whether the fragments align:\n",
    "   - `fragment_1` ends without proper punctuation, suggesting it is incomplete.\n",
    "   - `fragment_2` begins with 'des 10. Mai,' which continues the context of time introduced in `fragment_1`.\n",
    "   - Only the portion necessary to complete `fragment_1` was selected from `german_page_2` to form `fragment_2`.\n",
    "   - Combining them forms a coherent sentence: 'Der Angriff begann früh am Morgen des 10. Mai mit schwerem Artilleriefeuer.'\n",
    "<decision>The fragments align and form a coherent sentence.</decision>\n",
    "</thinking>\n",
    "\n",
    "<english>The attack began early in the morning on May 10th, with heavy artillery fire.</english>\n",
    "<final_fragment_2>des 10. Mai mit schwerem Artilleriefeuer.</final_fragment_2>\n",
    "\n",
    "------------------\n",
    "\n",
    "**Example 2. Two Consecutive, Unfragmented Sentences**\n",
    "\n",
    "<thinking>\n",
    "Step 1: Identify `fragment_1` from the bottom of `german_page_1`.\n",
    "<fragment_1>Jedenfalls ist der Umstand, daß sich General v. Falkenhayn in den überaus wichtigen Fragen des Einsatzes der Heeresreserve und der persönlichen Einflußnahme auf die Kriegsführung im Osten nicht durchsetzte, trotzdem aber in seiner Stellung als Chef des Generalstabes des Feldheeres verblieb, von folgenschwerer Bedeutung für sein ferneres Wirken gewesen.</fragment_1>\n",
    "\n",
    "Step 2: Identify `fragment_2` from the top of `german_page_2`.\n",
    "<fragment_2>I. Erwägungen und Maßnahmen der deutschen Obersten Heeresleitung.</fragment_2>\n",
    "\n",
    "Step 3: Validate whether the fragments align:\n",
    "   - `fragment_1` ends with a period, indicating it is a complete sentence.\n",
    "   - `fragment_2` begins with \"I. Erwägungen und Maßnahmen der deutschen Obersten Heeresleitung,\" which introduces a new topic unrelated to the context of `fragment_1`.\n",
    "   - The fragments are independent and do not logically or grammatically connect into a single sentence.\n",
    "<decision>The fragments do not align and do not form a single coherent sentence.</decision>\n",
    "</thinking>\n",
    "\n",
    "<english>In any case, the fact that General v. Falkenhayn did not prevail in the extremely important questions of the use of army reserves and personal influence on the conduct of the war in the East, but nevertheless remained in his position as Chief of the General Staff of the Field Army, was of momentous significance for his further work.</english>\n",
    "<final_fragment_2></final_fragment_2>\n",
    "\n",
    "------------------\n",
    "\n",
    "**Given Data:**\n",
    "<german_page_1>{german_body_contents[pageno]}</german_page_1>\n",
    "<german_page_2>{german_body_contents[next_pageno]}</german_page_2>\n",
    "<english_page_1>{english_body_contents[pageno]}</english_page_1>\n",
    "<german_sentence_fragment_1>{german_sentence_fragment_1}</german_sentence_fragment_1>\n",
    "\"\"\"\n",
    "              },\n",
    "            ]\n",
    "          },\n",
    "        ],\n",
    "        \"max_tokens\": 6000,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "\n",
    "    return payload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fee91b5-c14b-4a5e-afb2-8d9210b6be31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 01:05:55,898 - INFO - Processing i:0,  pageno: 001\n",
      "2024-12-29 01:06:01,631 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:01,633 - INFO - Processing i:1,  pageno: 002\n",
      "2024-12-29 01:06:05,826 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:05,828 - INFO - Processing i:2,  pageno: 003\n",
      "2024-12-29 01:06:21,916 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:21,918 - INFO - Processing i:3,  pageno: 004\n",
      "2024-12-29 01:06:26,408 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:26,410 - INFO - Processing i:4,  pageno: 005\n",
      "2024-12-29 01:06:36,648 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:36,650 - INFO - Processing i:5,  pageno: 006\n",
      "2024-12-29 01:06:45,763 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:45,765 - INFO - Processing i:6,  pageno: 007\n",
      "2024-12-29 01:06:55,695 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:06:55,697 - INFO - Processing i:7,  pageno: 008\n",
      "2024-12-29 01:07:06,858 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:07:06,860 - INFO - Processing i:8,  pageno: 009\n",
      "2024-12-29 01:07:18,733 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:07:18,734 - INFO - Processing i:9,  pageno: 010\n",
      "2024-12-29 01:07:30,819 - INFO - next round's fragment_2: sib., I. s. .......... = sibirisch,\n",
      "2024-12-29 01:07:30,821 - INFO - Processing i:10,  pageno: 011\n",
      "2024-12-29 01:07:41,364 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:07:41,366 - INFO - Processing i:11,  pageno: 012\n",
      "2024-12-29 01:07:46,950 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:07:46,952 - INFO - Processing i:12,  pageno: 013\n",
      "2024-12-29 01:07:58,263 - INFO - next round's fragment_2: \n",
      "2024-12-29 01:07:58,265 - INFO - Processing i:13,  pageno: 014\n",
      "2024-12-29 01:08:05,943 - INFO - next round's fragment_2: lichst schnell die Feldzugsentscheidung zu erzwingen.\n",
      "2024-12-29 01:08:05,944 - INFO - Processing i:14,  pageno: 015\n",
      "2024-12-29 01:08:15,568 - INFO - next round's fragment_2: 5. Armee, Generalmajor Schmidt v. Knobelsdorf, gewandt mit dem Ersuchen um Vorlage von Operationsentwürfen für eine neue Offensive im Westen, bei denen zur Voraussetzung gemacht war, daß „außer den in der Front stehenden und zum Halten derselben nötigen Truppen sechs Armeekorps mit reichlicher Munition zum Einsatz an beliebiger Stelle verfügbar sein würden“.\n",
      "2024-12-29 01:08:15,570 - INFO - Processing i:15,  pageno: 016\n",
      "2024-12-29 01:08:21,398 - INFO - next round's fragment_2: Durchhalten Österreich-Ungarns und der Türkei sowie die Entwicklung der Dinge auf dem Balkan abhängig.\n",
      "2024-12-29 01:08:21,400 - INFO - Processing i:16,  pageno: 017\n",
      "2024-12-29 01:08:28,172 - INFO - next round's fragment_2: der Infanterie Freiherrn v. Lyncker, in entgegengesetztem Sinne beraten war), lehnte indessen den Antrag des Reichskanzlers ab.\n",
      "2024-12-29 01:08:28,173 - INFO - Processing i:17,  pageno: 018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payloads, outputs\n\u001b[1;32m     49\u001b[0m english_texts_2 \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 50\u001b[0m payloads, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmain_broken_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-2024-08-06\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m, in \u001b[0;36mlog_execution_time_synchronous.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      6\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[52], line 38\u001b[0m, in \u001b[0;36mmain_broken_sentences\u001b[0;34m(model_name, headers)\u001b[0m\n\u001b[1;32m     36\u001b[0m payload \u001b[38;5;241m=\u001b[39m construct_payload_2(german_body_contents, english_body_contents, fragment_2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-2024-08-06\u001b[39m\u001b[38;5;124m\"\u001b[39m, pageno, next_pageno)\n\u001b[1;32m     37\u001b[0m payloads[pageno] \u001b[38;5;241m=\u001b[39m payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mmake_gpt_request_for_broken_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpageno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m outputs[pageno] \u001b[38;5;241m=\u001b[39m content\n\u001b[1;32m     40\u001b[0m fragment_2 \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<final_fragment_2>(.*?)</final_fragment_2>\u001b[39m\u001b[38;5;124m'\u001b[39m, content, re\u001b[38;5;241m.\u001b[39mDOTALL)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m, in \u001b[0;36mmake_gpt_request_for_broken_sentences\u001b[0;34m(model_name, headers, payload, pageno)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_gpt_request_for_broken_sentences\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, headers: \u001b[38;5;28mdict\u001b[39m, payload: \u001b[38;5;28mdict\u001b[39m, pageno: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m english_texts_2\n\u001b[0;32m---> 14\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://api.openai.com/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     20\u001b[0m     content \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/code/fraktur/.venv/lib/python3.10/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "import requests\n",
    "\n",
    "def log_execution_time_synchronous(func: Callable):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        logger.info(f\"Finished {func.__name__} in {time.time() - start:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def make_gpt_request_for_broken_sentences(model_name: str, headers: dict, payload: dict, pageno: str) -> dict:\n",
    "    global english_texts_2\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        json=payload,\n",
    "        headers=headers\n",
    "    )\n",
    "    result = response.json()\n",
    "    content = result['choices'][0]['message']['content']\n",
    "    english_texts_2[pageno] = re.search(r'<english>(.*?)</english>', content, re.DOTALL).group(1)\n",
    "    return content\n",
    "\n",
    "@log_execution_time_synchronous\n",
    "def main_broken_sentences(model_name, headers):\n",
    "    global payloads, outputs\n",
    "    fragment_2 = ''\n",
    "    for i in range(len(all_pagenos)):\n",
    "        pageno = all_pagenos[i]\n",
    "        next_pageno = all_pagenos[i+1]\n",
    "        if pageno in english_texts_2.keys():\n",
    "            logger.info(f'Skipping pageno: {pageno}')\n",
    "            continue\n",
    "        try:\n",
    "            logger.info(f\"Processing i:{i},  pageno: {pageno}\")\n",
    "            payload = construct_payload_2(german_body_contents, english_body_contents, fragment_2, \"gpt-4o-2024-08-06\", pageno, next_pageno)\n",
    "            payloads[pageno] = payload['messages'][1]['content'][0]['text']\n",
    "            content = make_gpt_request_for_broken_sentences(model_name, headers, payload, pageno)\n",
    "            outputs[pageno] = content\n",
    "            fragment_2 = re.search(r'<final_fragment_2>(.*?)</final_fragment_2>', content, re.DOTALL).group(1)\n",
    "            logger.info(f\"next round's fragment_2: {fragment_2}\") \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing pageno {pageno}: {e}\")\n",
    "            ipdb.set_trace()\n",
    "            pass\n",
    "\n",
    "    return payloads, outputs\n",
    "\n",
    "english_texts_2 = {}\n",
    "payloads, outputs = main_broken_sentences(\"gpt-4o-2024-08-06\", headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb6cb649-1c0b-48a5-8d50-3c21c6e0dc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Die Winterschlacht in Masuren . . . . . . . . . . . . . . . . . 172\n",
      "[Detailed subsections a-h with page numbers]\n",
      "4. Schutz der rechten Flanke der 10. Armee . . . . . . . . . . . . 243\n",
      "[Subsections a-b]\n",
      "5. Neuer Entschluß des Oberbefehlshabers Ost (22. bis 27. Februar 1915) 257\n",
      "[Sections 6-10]\n",
      "Wechselnde Pläne des Generals v. Falkenhayn . . . . . . . . . . . 301\n",
      "Die Schaffung einer neuen Heeresreserve . . . . . . . . . . . . . 301\n",
      "Erwägungen für einen kriegsentscheidenden Durchbruch im Westen . . 307\n",
      "Die politische Lage und ihr Einfluß auf die militärischen Entschließungen . . . . . . . . . . . . . . . . . . . . . . . 323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body = re.search(r'<body>(.*?)</body>', german_texts['006'], re.DOTALL).group(1) \n",
    "body\n",
    "german_body_contents['006']\n",
    "german_texts['006']\n",
    "print(german_body_contents['006'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b0aa1-1c12-488a-88fe-00c1dc63ccae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340658ae-e7d1-4811-a846-e67b369735f1",
   "metadata": {},
   "source": [
    "```\n",
    "2024-12-28 19:32:18,093 - INFO - Processing i:0,  pageno: 001\n",
    "2024-12-28 19:32:22,620 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:32:22,622 - INFO - Processing i:1,  pageno: 002\n",
    "2024-12-28 19:32:25,996 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:32:25,998 - INFO - Processing i:2,  pageno: 003\n",
    "2024-12-28 19:32:33,684 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:32:33,686 - INFO - Processing i:3,  pageno: 004\n",
    "2024-12-28 19:32:37,773 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:32:37,775 - INFO - Processing i:4,  pageno: 005\n",
    "2024-12-28 19:32:49,039 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:32:49,041 - INFO - Processing i:5,  pageno: 006\n",
    "2024-12-28 19:32:57,111 - ERROR - Error processing pageno 006: 'NoneType' object has no attribute 'group'\n",
    "2024-12-28 19:32:57,113 - INFO - Processing i:6,  pageno: 007\n",
    "2024-12-28 19:33:04,234 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:33:04,236 - INFO - Processing i:7,  pageno: 008\n",
    "2024-12-28 19:33:13,204 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:33:13,206 - INFO - Processing i:8,  pageno: 009\n",
    "2024-12-28 19:33:25,822 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:33:25,825 - INFO - Processing i:9,  pageno: 010\n",
    "2024-12-28 19:33:43,241 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:33:43,244 - INFO - Processing i:10,  pageno: 011\n",
    "2024-12-28 19:33:50,170 - ERROR - Error processing pageno 011: 'NoneType' object has no attribute 'group'\n",
    "2024-12-28 19:33:50,172 - INFO - Processing i:11,  pageno: 012\n",
    "2024-12-28 19:33:53,184 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:33:53,186 - INFO - Processing i:12,  pageno: 013\n",
    "2024-12-28 19:34:01,060 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:34:01,062 - INFO - Processing i:13,  pageno: 014\n",
    "2024-12-28 19:34:10,548 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:34:10,550 - INFO - Processing i:14,  pageno: 015\n",
    "2024-12-28 19:34:17,224 - INFO - next round's final_fragment_2: 5. Armee, Generalmajor Schmidt v. Knobelsdorf, gewandt mit dem Ersuchen um Vorlage von Operationsentwürfen für eine neue Offensive im Westen, bei denen zur Voraussetzung gemacht war, daß „außer den in der Front stehenden und zum Halten derselben nötigen Truppen sechs Armeekorps mit reichlicher Munition zum Einsatz an beliebiger Stelle verfügbar sein würden“.\n",
    "2024-12-28 19:34:17,226 - INFO - Processing i:15,  pageno: 016\n",
    "2024-12-28 19:34:21,635 - INFO - next round's final_fragment_2: Durchhalten Österreich-Ungarns und der Türkei sowie die Entwicklung der Dinge auf dem Balkan abhängig.\n",
    "2024-12-28 19:34:21,636 - INFO - Processing i:16,  pageno: 017\n",
    "2024-12-28 19:34:27,025 - INFO - next round's final_fragment_2: der Infanterie Freiherrn v. Lyncker, in entgegengesetztem Sinne beraten war), lehnte indessen den Antrag des Reichskanzlers ab.\n",
    "2024-12-28 19:34:27,027 - INFO - Processing i:17,  pageno: 018\n",
    "2024-12-28 19:34:36,183 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:34:36,185 - INFO - Processing i:18,  pageno: 019\n",
    "2024-12-28 19:34:43,345 - INFO - next round's final_fragment_2: standpunkt des Verbündeten geltend gemacht: „Niemals dürfen ihm jedoch die österreichisch-ungarischen Armeen unterstellt werden, das wäre nicht nur aus nationalen und dynastischen, sondern auch aus politischen und operativen Gründen ganz unzulässig. Wir würden dann jede Freiheit des Handelns verlieren und wären auf Gnade und Ungnade ausgeliefert.“\n",
    "2024-12-28 19:34:43,347 - INFO - Processing i:19,  pageno: 020\n",
    "2024-12-28 19:34:49,391 - INFO - next round's final_fragment_2: Diese Darlegungen riefen den lebhaften Widerspruch des Generals v. Conrad hervor: „An Befriedigung der Wünsche Italiens“ — so drahtete er am 7. Januar nach Mézières zurück — „und gar in weitgehendem Maße ist nicht zu denken.\n",
    "2024-12-28 19:34:49,392 - INFO - Processing i:20,  pageno: 021\n",
    "2024-12-28 19:34:58,706 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:34:58,708 - INFO - Processing i:21,  pageno: 022\n",
    "2024-12-28 19:35:03,108 - INFO - next round's final_fragment_2: Oberbefehlshaber Ost auf Grund seiner kriegerischen Erfolge im Heere wie im Volke genoss,\n",
    "2024-12-28 19:35:03,110 - INFO - Processing i:22,  pageno: 023\n",
    "2024-12-28 19:35:07,920 - INFO - next round's final_fragment_2: meines Stabes bestimmt ist, glaube ich folgern zu dürfen, daß die Abkommandierung des Generalleutnants nur eine vorübergehende sein soll.\n",
    "2024-12-28 19:35:07,921 - INFO - Processing i:23,  pageno: 024\n",
    "2024-12-28 19:35:12,538 - INFO - next round's final_fragment_2: gen an Italien bereitfinden müsse.\n",
    "2024-12-28 19:35:12,540 - INFO - Processing i:24,  pageno: 025\n",
    "2024-12-28 19:35:16,128 - INFO - next round's final_fragment_2: gehend behoben werden.\n",
    "2024-12-28 19:35:16,130 - INFO - Processing i:25,  pageno: 026\n",
    "2024-12-28 19:35:23,518 - INFO - next round's final_fragment_2: in Ostpreußen nur „größere örtliche Erfolge“ im Gegensatz zu den Führern im Osten, die von diesen Operationen bei genügend starkem Krafteinsatz eine entscheidenden Umschwingung der Kriegslage erhofften.\n",
    "2024-12-28 19:35:23,520 - INFO - Processing i:26,  pageno: 027\n",
    "2024-12-28 19:35:27,573 - INFO - next round's final_fragment_2: \n",
    "2024-12-28 19:35:27,575 - INFO - Processing i:27,  pageno: 028\n",
    "2024-12-28 19:35:32,498 - INFO - next round's final_fragment_2: v. Falkenhayn aufs neue zu Sicherungsmaßnahmen Anlaß gab.\n",
    "2024-12-28 19:35:32,500 - INFO - Processing i:28,  pageno: 029\n",
    "2024-12-28 19:35:39,892 - INFO - next round's final_fragment_2: Gründen das Zurücknehmen einer oder mehrerer Armeen in eine weiter rückwärts liegende Stellung notwendig werden, so werden rechtzeitig die hierfür erforderlichen Anweisungen von der Obersten Heeresleitung ergehen; für den Ausbau einer rückwärtigen Stellung seitens der Armee in dem hier gedachten Sinne kommt dieser Fall nicht in Betracht.\n",
    "2024-12-28 19:35:39,894 - INFO - Processing i:29,  pageno: 030\n",
    "2024-12-28 19:35:48,984 - INFO - next round's final_fragment_2: weit seine Steigerung bei ernsten Angriffsoperationen die Infanterie zwingen werde, sich durch tieferes Eingraben in neuartigen Anlagen oder durch größere Verteilung der Deckungen nach rückwärts zu schützen, mußte der Truppenerfahrung überlassen bleiben.\n",
    "2024-12-28 19:35:48,985 - INFO - Finished main_broken_sentences in 210.89 seconds.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323dc2c-273f-4526-9c75-39a324aef01a",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7002a4-1d69-4b0e-b4e5-953718c21cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
