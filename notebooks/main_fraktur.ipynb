{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce99f5d9-4191-4c1c-81d8-1eb78e165ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # split the pdf into separate pages\n",
    "\n",
    "# import PyPDF2\n",
    "# from src.document_generation import setup_logger\n",
    "# import logging\n",
    "\n",
    "# logger = logging.getLogger('logger_name')\n",
    "# if logger.hasHandlers():\n",
    "#     logger.handlers.clear()  # Clear existing handlers to avoid duplicates\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "# handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "# logger.addHandler(handler)\n",
    "# logger.propagate = False\n",
    "\n",
    "# # Input PDF file path\n",
    "# input_pdf_path = \"../input_data/Der Weltkrieg v7 East Front.pdf\"\n",
    "# output_folder = \"../input_data/Der Weltkrieg v7\"\n",
    "\n",
    "# # Ensure the output folder exists\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Open the PDF and split pages\n",
    "# try:\n",
    "#     with open(input_pdf_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         num_pages = len(pdf_reader.pages)\n",
    "#         logger.info(f\"Extracted {num_pages} pages from PDF\")\n",
    "\n",
    "#         for i, page in enumerate(pdf_reader.pages):\n",
    "#             # Create a new PDF writer for each page\n",
    "#             pdf_writer = PyPDF2.PdfWriter()\n",
    "#             pdf_writer.add_page(page)\n",
    "\n",
    "#             # Save the current page to a new file\n",
    "#             output_file_path = os.path.join(output_folder, f\"page_{i+1:03d}.pdf\")\n",
    "#             with open(output_file_path, 'wb') as output_file:\n",
    "#                 pdf_writer.write(output_file)\n",
    "            \n",
    "#             logger.debug(f\"Saved page {i+1} to {output_file_path}\")\n",
    "#             if i == 10:\n",
    "#                 break\n",
    "\n",
    "#     logger.info(f\"All pages have been split and saved to {output_folder}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd7026f-2a85-4c43-8110-547d0decaa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /Users/ozkansafak/code/fraktur/.venv/bin/python3\n",
      "sys.version: 3.10.9 (main, Mar  1 2023, 12:20:14) [Clang 14.0.6 ] \n",
      "\n",
      "CPU times: user 898 ms, sys: 2.52 s, total: 3.42 s\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard Python modules\n",
    "import time \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import openai\n",
    "import logging\n",
    "from typing import Dict, Tuple, List, Callable\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Decorator to log wall time\n",
    "def log_execution_time(func: Callable):\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = await func(*args, **kwargs)\n",
    "        logger.info(f\"Finished {func.__name__} in {time.time() - start:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def get_missing_keys(raw_german_texts):\n",
    "    # print missing keys\n",
    "    missing_keys = [ key for key in sorted(all_pagenos) if key not in raw_german_texts or len(raw_german_texts[key]) < 10 ]\n",
    "    return missing_keys\n",
    "\n",
    "# Load environment variables from .env file\n",
    "env_path = Path('../.env')  # Adjust path if needed\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# # Get the root path of the project\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Display and plotting\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Project imports\n",
    "from src.utils import timeit, encode_image, plt, pylab\n",
    "from src.processing import compute_log_spectrum_1d, extract_image_bbox, save_images\n",
    "from src.api_requests import construct_payload, process_single_page\n",
    "from src.document_generation import save_document\n",
    "\n",
    "# Set notebook display width\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# Print Python environment info\n",
    "print('sys.executable:', sys.executable)\n",
    "print('sys.version:', sys.version, '\\n')\n",
    "\n",
    "# Setup for PDF processing\n",
    "foldername = \"Der Weltkrieg v7\"\n",
    "\n",
    "# OpenAI API setup\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "}\n",
    "\n",
    "# --------------------\n",
    "# Initialize variables\n",
    "# --------------------\n",
    "plotter = False\n",
    "image_path = f\"../input_data/{foldername}/*pdf\"\n",
    "fnames = sorted(glob.glob(image_path))\n",
    "all_pagenos = [re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1) for fname in fnames]\n",
    "\n",
    "# Storage for processed texts\n",
    "raw_german_texts: Dict[str, str] = {}\n",
    "german_texts: Dict[str, str] = {}\n",
    "english_texts: Dict[str, str] = {}\n",
    "\n",
    "# ------------------\n",
    "# Configure logging\n",
    "# ------------------\n",
    "logger = logging.getLogger(\"time_logger\")\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()  # Clear existing handlers to avoid duplicates\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Don't propagate message to parent loggers\n",
    "logger.propagate = False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e18f5",
   "metadata": {},
   "source": [
    "---\n",
    "## Fraktur Translator (GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1adb975a-b3e6-4d87-904b-48b7095f2bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:06:53,617 - INFO - main: len(tasks): 2 -- Processing tasks as they complete\n",
      "2024-12-21 19:07:23,058 - INFO -    0 of 2 -- Successfully processed page:005\n",
      "2024-12-21 19:08:25,485 - INFO - Pageno: 006, \"raw_german\" section was not found\n",
      "2024-12-21 19:08:25,487 - INFO - Pageno: 006, \"german\" section was not found\n",
      "2024-12-21 19:08:25,488 - INFO - Pageno: 006, \"english\" section was not found\n",
      "2024-12-21 19:08:25,494 - INFO -    1 of 2 -- Successfully processed page:006\n",
      "2024-12-21 19:08:25,495 - INFO - Finished main in 91.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "@log_execution_time\n",
    "async def main(fnames, model_name=\"\", semaphore_count=5, extract=True):\n",
    "    semaphore = asyncio.Semaphore(semaphore_count)  # Adjust number based on API limits\n",
    "    async def _process_page(fname: str) -> Tuple[str, Dict]:\n",
    "        global raw_german_texts, german_texts, english_texts  # Explicitly declare globals\n",
    "        async with semaphore:\n",
    "            pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "            result = await process_single_page(fname, model_name, headers, plotter, pageno, extract) \n",
    "            return pageno, result\n",
    "    \n",
    "    # A list of coroutine objects. include only the unprocessed pages.\n",
    "    keys = set(raw_german_texts.keys())\n",
    "    tasks = []\n",
    "    for fname in fnames:\n",
    "        pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "        if pageno not in keys:\n",
    "            tasks.append(_process_page(fname))\n",
    "    logger.info(f\"main: len(tasks): {len(tasks)} -- Processing tasks as they complete\")\n",
    "    \n",
    "    # Process tasks as they complete\n",
    "    for i, completed_task in enumerate(asyncio.as_completed(tasks)):\n",
    "        try:\n",
    "            pageno, (content, raw_german_text, german_text, english_text) = await completed_task\n",
    "            raw_german_texts[pageno] = raw_german_text\n",
    "            german_texts[pageno] = german_text\n",
    "            english_texts[pageno] = english_text\n",
    "            logger.info(f\" {i:3d} of {len(tasks)} -- Successfully processed page:{pageno}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{i:3d} of {len(tasks)} -- Error processing a task: {e}\")\n",
    "    return \n",
    "\n",
    "# Run the async code\n",
    "await main(fnames[5:8], model_name=\"gpt-4o-2024-08-06\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bdf17-5961-49e5-a101-cccfe6cded0c",
   "metadata": {},
   "source": [
    "##  Handle missing keys (Claude Sonnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004d68e6-4fd4-4a7d-bf9b-cf220be5f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:08:28,415 - INFO - main: len(tasks): 2 -- Processing tasks as they complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: {'006', '405'}\n",
      "processing pageno: 006\n",
      "processing pageno: 405\n",
      "missed_fnames: \n",
      "../input_data/Der Weltkrieg v7/page_006.pdf\n",
      "../input_data/Der Weltkrieg v7/page_405.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:08:33,906 - INFO - Pageno: 405, \"raw_german\" section was not found\n",
      "2024-12-21 19:08:33,908 - INFO - Pageno: 405, \"german\" section was not found\n",
      "2024-12-21 19:08:33,909 - INFO - Pageno: 405, \"english\" section was not found\n",
      "2024-12-21 19:08:35,270 - INFO -    0 of 2 -- Successfully processed page:405\n",
      "2024-12-21 19:08:59,328 - INFO -    1 of 2 -- Successfully processed page:006\n",
      "2024-12-21 19:08:59,329 - INFO - Finished main in 30.91 seconds.\n",
      "2024-12-21 19:08:59,332 - INFO - main: len(tasks): 1 -- Processing tasks as they complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: {'405'}\n",
      "processing pageno: 405\n",
      "missed_fnames: \n",
      "../input_data/Der Weltkrieg v7/page_405.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:09:03,858 - INFO - Pageno: 405, \"raw_german\" section was not found\n",
      "2024-12-21 19:09:03,860 - INFO - Pageno: 405, \"german\" section was not found\n",
      "2024-12-21 19:09:03,861 - INFO - Pageno: 405, \"english\" section was not found\n",
      "2024-12-21 19:09:03,866 - INFO -    0 of 1 -- Successfully processed page:405\n",
      "2024-12-21 19:09:03,867 - INFO - Finished main in 4.53 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# 1. Rerun the missing pages on Claude\n",
    "# ---------------------\n",
    "missing_keys = set(get_missing_keys(raw_german_texts))\n",
    "for key in missing_keys:\n",
    "    del raw_german_texts[key]\n",
    "print(f\"missing_keys: {missing_keys}\")\n",
    "missed_fnames = []\n",
    "for fname in fnames:\n",
    "    pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "    if pageno in missing_keys:\n",
    "        print(f\"processing pageno: {pageno}\")\n",
    "        missed_fnames.append(fname)\n",
    "print(f\"missed_fnames: \")\n",
    "[print(item) for item in missed_fnames]\n",
    "\n",
    "await main(missed_fnames, model_name=\"claude-3-5-sonnet-20241022\", semaphore_count=1, extract=True)\n",
    "\n",
    "# ---------------------\n",
    "# 2. If there still are missing pages, run them without performing FFT based extraction. \n",
    "#    This time compute missing_keys based on 'english_texts'.\n",
    "# ---------------------\n",
    "missing_keys = set(get_missing_keys(english_texts))\n",
    "for key in missing_keys:\n",
    "    del raw_german_texts[key]\n",
    "print(f\"missing_keys: {missing_keys}\")\n",
    "missed_fnames = []\n",
    "for fname in fnames:\n",
    "    pageno = re.search(r'page_(.*?)\\.pdf', fname, re.DOTALL).group(1)\n",
    "    if pageno in missing_keys:\n",
    "        print(f\"processing pageno: {pageno}\")\n",
    "        missed_fnames.append(fname)\n",
    "print(f\"missed_fnames: \")\n",
    "for item in missed_fnames:\n",
    "    print(item) \n",
    "\n",
    "await main(missed_fnames, model_name=\"claude-3-5-sonnet-20241022\", semaphore_count=1, extract=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420883ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save json files and .docx files.\n",
    "\n",
    "from src.document_generation import save_document\n",
    "\n",
    "# save json outputs\n",
    "# if not os.path.exists(f'../output_data/{foldername}'):\n",
    "#     os.makedirs(f'../output_data/{foldername}')\n",
    "# with open(f'../output_data/{foldername}/english_texts.json', 'w') as f:\n",
    "#     json.dump(english_texts, f)\n",
    "# with open(f'../output_data/{foldername}/german_texts.json', 'w') as f:\n",
    "#     json.dump(german_texts, f)\n",
    "# with open(f'../output_data/{foldername}/raw_german_texts.json', 'w') as f:\n",
    "#     json.dump(raw_german_texts, f)\n",
    "\n",
    "doc1, fname1 = save_document(german_texts, foldername, language='German')\n",
    "doc2, fname2 = save_document(english_texts, foldername, language='English')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63eac8",
   "metadata": {},
   "source": [
    "``` \n",
    "1.  Upload Input folder of pdfs to blob storage.\n",
    "2.  Read file from s3.\n",
    "3.  FFT in y -> (x_hi, x_lo), write half_cropped_image to s3\n",
    "4.  FFT in x -> (y_hi, y_lo), write cropped_image to s3\n",
    "5.  Read cropped image from s3 -> encode_image -> translate and transcribe -> JSON output\n",
    "\n",
    "```\n",
    "\n",
    "### Available models and pricing:\n",
    "```\n",
    "\"gpt-4o-2024-08-06\":\n",
    "    \"price_txt\": \"$2.50 / 1M input tokens\"\n",
    "    \"price_img\": \"$0.001913 / 1500px^2\"\n",
    "    \n",
    "\"gpt-4o-mini-2024-07-18\":\n",
    "    \"price_txt\": \"$0.150 / 1M input tokens\"\n",
    "    \"price_img\": \"$0.003825 / 1500px^2\"\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6e3a6-1c7d-4cce-badb-8b664f6e75c8",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the German text and translate broken sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d4a46058-0503-4b3a-a1b6-c748b9d1cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../output_data/{foldername}/english_texts.json', 'r') as f:\n",
    "    english_texts = json.load(f)\n",
    "with open(f'../output_data/{foldername}/german_texts.json', 'r') as f:\n",
    "    german_texts = json.load(f)\n",
    "with open(f'../output_data/{foldername}/raw_german_texts.json', 'r') as f:\n",
    "    raw_german_texts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f23f10ed-d003-451c-8d19-27092ada0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_payload_2(german_page_contents, english_page_contents, model_name, i):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a World War II historian and a professional translator from GERMAN to ENGLISH who \"\n",
    "              \"stays loyal to both the style and the character of the original German text.\"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"<german_page_1>{german_page_contents[i]}</german_page_1>\\n\"\n",
    "                  f\"<german_page_2>{german_page_contents[i+1]}</german_page_2>\\n\" \n",
    "                  f\"<english_page_1>{english_page_contents[i]}</english_page_1>\\n\" \n",
    "                  \"---------------------------------------------------------------\\n\"\n",
    "                  \"I provided two succesive german pages from a World War II history book. \"\n",
    "                  \"I had an AI assistant translate the german pages for me. \"\n",
    "                  \"(I included the English translation of 'german_page_1' inside the 'english_page_1' tags. \"\n",
    "                  \"Unfortunately, the translation was made in isolation from one another \"\n",
    "                  \"--i.e. the AI assistant I used was only able to see one page at a time. \"\n",
    "                  \"This is a problem because \"\n",
    "                  \"if there's a sentence that spans over two successive german pages, the sentences are fragmented. \"\n",
    "                  \"This means the AI assistant couldnt translate the german sentence coherently as a whole, and \"\n",
    "                  \"it translated the fragmented parts separately. \\n\"\n",
    "                  \"\\n\"\n",
    "                  \"I want you to re-translate the content of 'german_page_1' from German to English.\\n\"\n",
    "                  \n",
    "                  \"**Rule 1:** If the value inside the '<first_sentence_was_fragmented>' tags above is a 'True' value \"\n",
    "                  \"then omit the first sentence at the beginning of the <body> section because it's not a whole sentence. \"\n",
    "                  \"(cut off from the previous page), exclude it from the translation.\\n\"\n",
    "                  \n",
    "                  \"**Rule 2:** If the last sentence of 'german_page_1' extends into 'german_page_2', \"\n",
    "                  \"include this full sentence in the translation as if it were fully a part of 'german_page_1'. \"\n",
    "                  \"And in this case, pay attention to only include this one sentence that spans over the end of 'german_page_1' \"\n",
    "                  \"and beginning of 'german_page_2'. And don't engulf the next whole sentence from the 'german_page_2' into 'german_page_1'.\\n\"\n",
    "                  \n",
    "                  \"**Rule 3:** Do not change the translation of the rest of the 'german_page_1'. For this purpose, I included its translation \"\n",
    "                  \"in the tags <english_page_1></english_page_1> \"\n",
    "                  \"which I want you to use as guidance, so you stay loyal to the style and linguistic characteristics and \"\n",
    "                  \"you don't re-interprete or re-translate the intact sentences of 'german_page_1' \\n\"\n",
    "                  \n",
    "                  \"**Rule 4:** Copy the '<header>' and '<footer>' sections from 'english_page_1' to 'german_page_1' exactly.\"\n",
    "                  \n",
    "                  \"**Formatting:** \"\n",
    "                  \"As mentioned above, if the last sentence of 'german_page_1' is fragmented (the end of the sentence extends into second page), \"\n",
    "                  \"then start your output with these tags:\\n\"\n",
    "                  \"<last_sentence_is_fragmented>True</last_sentence_is_fragmented> \"\n",
    "                  \"otherwise start your output with these tags:\\n\"\n",
    "                  \"<last_sentence_is_fragmented>False</last_sentence_is_fragmented>. \"\n",
    "                  \"Then continue on with your task of translation and wrap the output in <english></english> tags.\\n\"\n",
    "                  \"Maintain the 'header' and 'footer' sections as is in the 'english_page_1'. \\n\"\n",
    "              },\n",
    "            ]\n",
    "          }\n",
    "        ],\n",
    "        \"max_tokens\": 6000,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d163db8d-30ce-4a2e-b440-8c69b752a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_page_contents = [german_texts[pageno] for pageno in all_pagenos]\n",
    "english_page_contents = [english_texts[pageno] for pageno in all_pagenos]\n",
    "payloads = []\n",
    "for i in range(len(all_pagenos)-1):\n",
    "    payloads.append(construct_payload_2(german_page_contents, english_page_contents, \"gpt-4o-2024-08-06\", i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "59a9550e-9568-4bd9-9b50-2067ebc748a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 03:56:28,596 - INFO - main: len(tasks): 15 -- Processing tasks as they complete\n",
      "2024-12-27 03:56:39,015 - INFO -    0 of 15 -- Successfully processed pageno:201\n",
      "2024-12-27 03:56:47,411 - INFO -    1 of 15 -- Successfully processed pageno:202\n",
      "2024-12-27 03:56:57,857 - INFO -    2 of 15 -- Successfully processed pageno:203\n",
      "2024-12-27 03:57:07,891 - INFO -    3 of 15 -- Successfully processed pageno:204\n",
      "2024-12-27 03:57:13,309 - INFO -    4 of 15 -- Successfully processed pageno:205\n",
      "2024-12-27 03:57:23,046 - INFO -    5 of 15 -- Successfully processed pageno:206\n",
      "2024-12-27 03:57:32,578 - INFO -    6 of 15 -- Successfully processed pageno:207\n",
      "2024-12-27 03:57:41,072 - INFO -    7 of 15 -- Successfully processed pageno:208\n",
      "2024-12-27 03:57:53,267 - INFO -    8 of 15 -- Successfully processed pageno:209\n",
      "2024-12-27 03:58:12,378 - INFO -    9 of 15 -- Successfully processed pageno:210\n",
      "2024-12-27 03:58:20,276 - INFO -   10 of 15 -- Successfully processed pageno:211\n",
      "2024-12-27 03:58:25,921 - INFO -   11 of 15 -- Successfully processed pageno:212\n",
      "2024-12-27 03:58:34,624 - INFO -   12 of 15 -- Successfully processed pageno:213\n",
      "2024-12-27 03:58:45,268 - INFO -   13 of 15 -- Successfully processed pageno:214\n",
      "2024-12-27 03:58:52,752 - INFO -   14 of 15 -- Successfully processed pageno:215\n",
      "2024-12-27 03:58:52,753 - INFO - Finished main_broken_sentences in 144.16 seconds.\n"
     ]
    }
   ],
   "source": [
    "async def make_gpt_request_for_broken_sentences(model_name: str, headers: dict, payload: dict, pageno: str) -> dict:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        global english_texts_2\n",
    "        async with session.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            json=payload,\n",
    "            headers=headers\n",
    "        ) as response:\n",
    "            result = await response.json()\n",
    "            content = result['choices'][0]['message']['content']\n",
    "            english_texts_2[pageno] = re.search(f'<english>(.*?)</english>', content, re.DOTALL).group(1)\n",
    "            return result\n",
    "\n",
    "@log_execution_time\n",
    "async def main_broken_sentences(model_name, headers, payloads):\n",
    "    semaphore = asyncio.Semaphore(3)  # Adjust number based on API limits\n",
    "    async def _process_page(model_name, headers, payload, pageno) -> dict:\n",
    "        async with semaphore:\n",
    "            await make_gpt_request_for_broken_sentences(model_name, headers, payload, pageno) \n",
    "            return pageno\n",
    "\n",
    "    # A list of coroutine objects. include only the unprocessed pages.\n",
    "    tasks = []\n",
    "    for i in range(200, 215):\n",
    "        tasks.append(_process_page(model_name, headers, payloads[i], all_pagenos[i])) \n",
    "\n",
    "    logger.info(f\"main: len(tasks): {len(tasks)} -- Processing tasks as they complete\") \n",
    "\n",
    "    # Process tasks as they complete\n",
    "    for i, task in enumerate(tasks):\n",
    "        try:\n",
    "            pageno = await task\n",
    "            logger.info(f\" {i:3d} of {len(tasks)} -- Successfully processed pageno:{pageno}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{i:3d} of {len(tasks)} -- Error processing a task: {e}\")\n",
    "\n",
    "# Run the async code\n",
    "english_texts_2 = {}\n",
    "await main_broken_sentences(\"gpt-4o-2024-08-06\", headers, payloads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3d6321e9-6ba9-4947-a11d-1df5ffc915a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageno: 201\n",
      "--------------------------------------------\n",
      "ORIGINAL:\n",
      "\n",
      "<header>The Winter Masurian Battle.</header>\n",
      "<body>February 25th departed to Lyk for the 8th Army. At Tauroggen, only the weak Hoffmann detachment secured¹).\n",
      "In this grouping, the 10th Army had to repel the fierce Russian attacks of the coming days. Constant reinforcement on the enemy side gradually led to a balance of the situation. There were days of bitter local battles, in which the previous victor and attacker were completely pushed into defense.\n",
      "The intention of the 10th Army High Command, on February 24th, to attack from the Augustowfski Canal to Rygalowka with the XXXVIII and XXXX Reserve Corps as well as the 2nd Infantry Division, did not come to fruition, as in the early morning hours of February 23rd, the Russians succeeded in crossing the lowlands before the 4th Cavalry Division and advancing further towards Lissow and Wrotnik. General Litzmann therefore had to request the support of the 75th Reserve Division and move parts of his two divisions to the endangered section. General v. der Marwitz took command of the 75th Reserve Division 4th Cavalry Division. Likewise, the 76th Reserve Division was pushed west to the railway. The orders for the counterattack were based on the idea of cutting off the enemy who had crossed from the crossing points or at least gaining the southern bank simultaneously with the retreating enemy. However, before the movements on the few and poor roads were carried out, the Russians further expanded their successes on February 24th. The situation became critical. Yet, after fierce fighting during the course of this day, with the reinforcements of the 75th, 76th, and 79th Reserve Divisions, it was possible to push the Russians back over the section. Only Stabin remained in their hands. At Czarniewo, the 75th Reserve Division pursued the enemy over two Bobr arms; but before the last, their strength was exhausted. Simultaneously, a Russian attack at Jatszembna was repelled by the 80th Reserve Division.\n",
      "The Army High Command now believed that forcing the crossing to the southern Bobr bank could most likely be achieved by the 75th Reserve Division. Therefore, on the morning of February 25th, it ordered General Litzmann to make all available parts of the 76th Reserve Division General v. der Marwitz available again.\n",
      "In the meantime, the 75th Reserve Division had restored the crossings over the two Bobr arms; the bridge at Dungly over the third river arm had been blown up by the Russians in time; here</body>\n",
      "<footer>¹) G. 243.</footer>\n",
      "\n",
      "--------------------------------------------\n",
      "FIXED:\n",
      "\n",
      "<header>The Winter Masurian Battle.</header>\n",
      "<body>February 25th departed to Lyk for the 8th Army. At Tauroggen, only the weak Hoffmann detachment secured¹).\n",
      "In this grouping, the 10th Army had to repel the fierce Russian attacks of the coming days. Constant reinforcement on the enemy side gradually led to a balance of the situation. There were days of bitter local battles, in which the previous victor and attacker were completely pushed into defense.\n",
      "The intention of the 10th Army High Command, on February 24th, to attack from the Augustowfski Canal to Rygalowka with the XXXVIII and XXXX Reserve Corps as well as the 2nd Infantry Division, did not come to fruition, as in the early morning hours of February 23rd, the Russians succeeded in crossing the lowlands before the 4th Cavalry Division and advancing further towards Lissow and Wrotnik. General Litzmann therefore had to request the support of the 75th Reserve Division and move parts of his two divisions to the endangered section. General v. der Marwitz took command of the 75th Reserve Division 4th Cavalry Division. Likewise, the 76th Reserve Division was pushed west to the railway. The orders for the counterattack were based on the idea of cutting off the enemy who had crossed from the crossing points or at least gaining the southern bank simultaneously with the retreating enemy. However, before the movements on the few and poor roads were carried out, the Russians further expanded their successes on February 24th. The situation became critical. Yet, after fierce fighting during the course of this day, with the reinforcements of the 75th, 76th, and 79th Reserve Divisions, it was possible to push the Russians back over the section. Only Stabin remained in their hands. At Czarniewo, the 75th Reserve Division pursued the enemy over two Bobr arms; but before the last, their strength was exhausted. Simultaneously, a Russian attack at Jatszembna was repelled by the 80th Reserve Division.\n",
      "The Army High Command now believed that forcing the crossing to the southern Bobr bank could most likely be achieved by the 75th Reserve Division. Therefore, on the morning of February 25th, it ordered General Litzmann to make all available parts of the 76th Reserve Division General v. der Marwitz available again.\n",
      "In the meantime, the 75th Reserve Division had restored the crossings over the two Bobr arms; the bridge at Dungly over the third river arm had been blown up by the Russians in time; here the 75th Reserve Division was stuck. The enemy fire was so intense that any movement on the 2 to 3 km long dam, which led through the swamp lowlands, had to cease.</body>\n",
      "<footer>¹) G. 243.</footer>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageno = sorted(english_texts_2.keys())[0]\n",
    "print('pageno:', pageno)\n",
    "\n",
    "print('--'*22)\n",
    "print('ORIGINAL:')\n",
    "print(english_texts[pageno])\n",
    "print('--'*22)\n",
    "print('FIXED:')\n",
    "print(english_texts_2[pageno]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "699cf026-e62f-4ec6-bc52-3e15be2958bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageno: 202  |  False\n",
      "--------------------------------------------\n",
      "ORIGINAL:\n",
      "\n",
      "<header>Successful Battles for the Bobr Section.</header>\n",
      "<body>The 75th Reserve Division was stuck. The enemy fire was so intense that any movement on the 2 to 3 km long dam, which led through the swamp depression, had to be avoided. An attack was only to be launched after thorough artillery preparation.\n",
      "In the middle section, the 4th Cavalry and 79th Reserve Division succeeded on February 25 in taking Stabbin after fierce local fighting and pushing the Russians back to the south bank. The enemy had cleared the north bank in front of the 80th Reserve Division. General Litzmann intended to advance over Ostrow at dawn on February 27 after consolidating stronger forces.\n",
      "However, the prospects for success continued to deteriorate. On February 25, the weak front parts of the 75th Reserve Division fell into captivity at Dwugly after bravely enduring enemy fire all day in the snow water of the Bobr swamp without assistance. On the orders of the Commander-in-Chief East, the 4th Cavalry Division and the two divisions of the XXVIII Reserve Corps had to be brought in for transfer to the threatened Narew front in the following days. General Litzmann now had to hold the long Bobr section from the canal to Lipit with his two divisions alone. Additionally, the further dwindling of combat strength was a factor; the strength of the battalions, which had to rush from one endangered point to another day and night in snow and swamp, partially sank to 220, 180, even to 78 rifles. Therefore, carrying out the attack was no longer conceivable.\n",
      "During this defense against strong Russian counterattacks at Bobr, the 2nd and 31st Infantry Divisions were also heavily attacked west of Grodno. General v. Below was eventually forced to reintegrate the 42nd Infantry Division into the front line. The focal point of the battles, where the Russians were supported by effective fire from the fortress guns of Grodno, was at the height 214 south of Kaplanowce, defended by the 31st Infantry Division. Holding it cost heavy sacrifices. General v. Below could not initially decide on their voluntary evacuation, as the height was the tactically most important point in the foreground of the fortress due to its good observation against Grodno.\n",
      "On the orders of the Commander-in-Chief East, a reinforced brigade of the XXI Army Corps was to be withdrawn for transport to Augustowo on the night of February 27. However, this defense encountered unexpected difficulties. At 6 a.m., a strong Russian attack hit the relief, which was now interrupted</body>\n",
      "\n",
      "--------------------------------------------\n",
      "FIXED:\n",
      "\n",
      "<header>Successful Battles for the Bobr Section.</header>\n",
      "<body>The 75th Reserve Division was stuck. The enemy fire was so intense that any movement on the 2 to 3 km long dam, which led through the swamp depression, had to be avoided. An attack was only to be launched after thorough artillery preparation.\n",
      "In the middle section, the 4th Cavalry and 79th Reserve Division succeeded on February 25 in taking Stabbin after fierce local fighting and pushing the Russians back to the south bank. The enemy had cleared the north bank in front of the 80th Reserve Division. General Litzmann intended to advance over Ostrow at dawn on February 27 after consolidating stronger forces.\n",
      "However, the prospects for success continued to deteriorate. On February 25, the weak front parts of the 75th Reserve Division fell into captivity at Dwugly after bravely enduring enemy fire all day in the snow water of the Bobr swamp without assistance. On the orders of the Commander-in-Chief East, the 4th Cavalry Division and the two divisions of the XXVIII Reserve Corps had to be brought in for transfer to the threatened Narew front in the following days. General Litzmann now had to hold the long Bobr section from the canal to Lipit with his two divisions alone. Additionally, the further dwindling of combat strength was a factor; the strength of the battalions, which had to rush from one endangered point to another day and night in snow and swamp, partially sank to 220, 180, even to 78 rifles. Therefore, carrying out the attack was no longer conceivable.\n",
      "During this defense against strong Russian counterattacks at Bobr, the 2nd and 31st Infantry Divisions were also heavily attacked west of Grodno. General v. Below was eventually forced to reintegrate the 42nd Infantry Division into the front line. The focal point of the battles, where the Russians were supported by effective fire from the fortress guns of Grodno, was at the height 214 south of Kaplanowce, defended by the 31st Infantry Division. Holding it cost heavy sacrifices. General v. Below could not initially decide on their voluntary evacuation, as the height was the tactically most important point in the foreground of the fortress due to its good observation against Grodno.\n",
      "On the orders of the Commander-in-Chief East, a reinforced brigade of the XXI Army Corps was to be withdrawn for transport to Augustowo on the night of February 27. However, this defense encountered unexpected difficulties. At 6 a.m., a strong Russian attack hit the relief, which was now interrupted. Terrain was lost, several batteries fell into enemy hands.</body>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageno = sorted(english_texts_2.keys())[1]\n",
    "print('pageno:', pageno, ' | ', english_texts_2[pageno] == english_texts[pageno])\n",
    "print('--'*22)\n",
    "print('ORIGINAL:')\n",
    "print(english_texts[pageno])\n",
    "print('--'*22)\n",
    "print('FIXED:')\n",
    "print(english_texts_2[pageno]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323dc2c-273f-4526-9c75-39a324aef01a",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7002a4-1d69-4b0e-b4e5-953718c21cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
